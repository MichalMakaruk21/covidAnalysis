{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "from IPython.display import display\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import sklearn.neighbors._base\n",
    "import sys\n",
    "sys.modules['sklearn.neighbors.base'] = sklearn.neighbors._base\n",
    "from missingpy import MissForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# The missingpy library is about to be updated, and it sends warnings not to leave some parameters at the default value\n",
    "from warnings import simplefilter\n",
    "simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "outputs": [],
   "source": [
    "# Data engineering part"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "outputs": [],
   "source": [
    "# Loading 2 data sources and 1 table used for aggregation by iso codes\n",
    "# The na_filter parameter is used because Namibia, has the iso2 code \"NA\" and the function reads this as nan\n",
    "\n",
    "vaccinationsDF = pd.read_csv('dataFiles/vaccinations.csv', sep=',', header=0, na_filter=False)\n",
    "casesDF = pd.read_csv('dataFiles/covidCases.csv', sep=',', header=0, na_filter=False)\n",
    "iso_codesDF = pd.read_csv('dataFiles/iso_codes.csv', sep=',', header=1, na_filter=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "outputs": [],
   "source": [
    "# Normalize the names of columns linking data\n",
    "# Filter iso codes by length for error elimination\n",
    "# Resetting an index after deleting columns\n",
    "\n",
    "casesDF.rename(columns={'Date_reported':'date', 'Country':'location', 'Country_code': 'iso2Code'}, inplace=True)\n",
    "\n",
    "vaccinationsDF.rename(columns={'iso_code': 'iso3Code'}, inplace=True)\n",
    "vaccinationsDF.drop(vaccinationsDF[(vaccinationsDF['iso3Code'].apply(len) != 3)].index, inplace=True)\n",
    "vaccinationsDF.reset_index(drop=True)\n",
    "\n",
    "iso_codesDF.drop(iso_codesDF.columns[[1, 2, 5, 6, 7]], axis=1, inplace=True)\n",
    "iso_codesDF.rename(columns={'Country name':'location', 'Alpha-2 code':'iso2Code', 'Alpha-3 code':'iso3Code'}, inplace=True)\n",
    "iso_codesDF = iso_codesDF.astype(str)\n",
    "iso_codesDF.drop(iso_codesDF[(iso_codesDF['iso2Code'].apply(len) != 2) | (iso_codesDF['iso3Code'].apply(len) != 3)].index, inplace=True)\n",
    "iso_codesDF = iso_codesDF.reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "outputs": [],
   "source": [
    "# Merging tables by iso codes.\n",
    "# The function is designed to merge multiple df's at once, but due to differences between the types of iso codes in the cases and vaccinations, I could not use its full potential.\n",
    "\n",
    "tmp_df = reduce(lambda left, right: pd.merge(left, right, on=['iso3Code'], how='inner'), [vaccinationsDF, iso_codesDF])\n",
    "df = reduce(lambda left, right: pd.merge(left, right, on=['iso2Code', 'date'], how='outer'), [tmp_df, casesDF])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "outputs": [],
   "source": [
    "# Converting date format to int\n",
    "df['date'] = pd.to_datetime(df['date'], format='%Y.%m.%d').apply(lambda x: x.toordinal())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "outputs": [],
   "source": [
    "# Removal of unnecessary columns after merging\n",
    "df = df.drop(['location_x', 'location_y', 'WHO_region', 'iso3Code', 'total_vaccinations_per_hundred', 'total_vaccinations_per_hundred', 'people_vaccinated_per_hundred', 'people_fully_vaccinated_per_hundred', 'total_boosters_per_hundred', 'daily_vaccinations_per_million', 'daily_people_vaccinated_per_hundred', 'daily_vaccinations_raw'], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "outputs": [],
   "source": [
    "# Removal of rows where the location is blank, this is due to writing the aggregation table in html form from the website and having records long for the entire table reporting on being an exclave or island of a country\n",
    "# Removal of the location column, from now on the model uses iso 2 code\n",
    "\n",
    "df = df.dropna(subset=['location'])\n",
    "df = df.drop(['location'], axis=1)\n",
    "df = df.reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "outputs": [],
   "source": [
    "# replace empty values with nan\n",
    "df = df.replace(r'^\\s*$', np.nan, regex=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "outputs": [],
   "source": [
    "# Conversion of columns to numeric type with the ability to store nan\n",
    "# Somehow function \"remove()\" does not work\n",
    "\n",
    "df_numeric_col = [x for x in df.columns.tolist() if x != 'iso2Code']\n",
    "df[df_numeric_col] = df[df_numeric_col].astype('Int64').astype('Float64')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "outputs": [],
   "source": [
    "# Function converting df_dummies back to regular df\n",
    "\n",
    "def undummify(df, prefix_sep=\"_\"):\n",
    "    cols2collapse = {\n",
    "        item.split(prefix_sep)[0]: (prefix_sep in item) for item in df.columns\n",
    "    }\n",
    "    series_list = []\n",
    "    for col, needs_to_collapse in cols2collapse.items():\n",
    "        if needs_to_collapse:\n",
    "            undummified = (\n",
    "                df.filter(like=col)\n",
    "                .idxmax(axis=1)\n",
    "                .apply(lambda x: x.split(prefix_sep, maxsplit=1)[1])\n",
    "                .rename(col)\n",
    "            )\n",
    "            series_list.append(undummified)\n",
    "        else:\n",
    "            series_list.append(df[col])\n",
    "    undummified_df = pd.concat(series_list, axis=1)\n",
    "    return undummified_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "outputs": [],
   "source": [
    "# Selection of sample European countries due to the amount of data and limited CPU power of my computer\n",
    "selected_countries = ['PL', 'DE', 'NO', 'BE', 'GB', 'UA']\n",
    "df_trimmed = df[df['iso2Code'].isin(selected_countries)]\n",
    "\n",
    "# For operations on full data, please comment the two lines above and uncomment the one below.\n",
    "\n",
    "# df_trimmed = df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "outputs": [],
   "source": [
    "# Transformation to dummies\n",
    "df_dummies = pd.get_dummies(df_trimmed)\n",
    "\n",
    "# Filling nan data as -1, the numerical interval of the data is in the interval of natural numbers. This is due to a problem with the MissForrest class and its method of type conversion\n",
    "df_dummies = df_dummies.fillna(-1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "outputs": [],
   "source": [
    "# Preprocessing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "outputs": [],
   "source": [
    "# Saving dummies columns and transformation df_dummies int an array\n",
    "df_dummies_columns = df_dummies.columns.tolist()\n",
    "df_array = df_dummies.to_numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "outputs": [],
   "source": [
    "# A Pipeline to supplement -1(as nan) values and standardize the dataset\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('imputer', MissForest(random_state=0, missing_values=-1, max_features='sqrt', criterion='squared_error', class_weight='balanced_subsample')),\n",
    "    ('std_scaler', StandardScaler())\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 6\n"
     ]
    }
   ],
   "source": [
    "# Pipeline execution\n",
    "df_array_transformed = pipeline.fit_transform(df_array)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "outputs": [],
   "source": [
    "# Save dataframe from transformed matrix using undummify function\n",
    "\n",
    "df_transformed = pd.DataFrame(data=df_array_transformed, columns=df_dummies_columns)\n",
    "df_transformed = undummify(df_transformed, prefix_sep='Code_')\n",
    "df_transformed.rename(columns={'iso2': 'iso2Code'}, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "outputs": [],
   "source": [
    "# Calculation of mortality rate based on the amount of total daily mortality and infectiousness\n",
    "df_transformed['mortality_rate'] = (df.Cumulative_deaths / df.Cumulative_cases) * 100"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "outputs": [],
   "source": [
    "# Re-conversion to dummy\n",
    "df_transformed = pd.get_dummies(df_transformed)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "outputs": [],
   "source": [
    "# Training of the machine learning model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "outputs": [],
   "source": [
    "X = np.array((df_transformed.drop(['mortality_rate'], axis=1)))\n",
    "y = np.array((df_transformed['mortality_rate']))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "outputs": [
    {
     "data": {
      "text/plain": "RandomForestRegressor(n_estimators=50, random_state=0)",
      "text/html": "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(n_estimators=50, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(n_estimators=50, random_state=0)</pre></div></div></div></div></div>"
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_reg = RandomForestRegressor(n_estimators=50, random_state=0)\n",
    "forest_reg.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "outputs": [],
   "source": [
    "# Prediction of mortality rate\n",
    "predicted_indicator = forest_reg.predict(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error score: 0.0920323594959131\n"
     ]
    }
   ],
   "source": [
    "# Error prediction rate\n",
    "print(f'Error score: {np.sqrt(mean_squared_error(predicted_indicator, y_test, squared=True))}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}